// This file handles GoogleGenAI API integration via the server API
import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from '@google/generative-ai';

interface TranscriptionResult {
  transcription: string;
  summary: string;
  tasks: {
    id: string;
    text: string;
    deadline: string;
  }[];
}

interface GeminiServiceConfig {
  apiKey?: string;
}

export class GeminiService {
  private genAI: GoogleGenerativeAI | null = null;
  private apiKey?: string;

  constructor(config: GeminiServiceConfig) {
    this.apiKey = config.apiKey;
    if (this.apiKey) {
      this.genAI = new GoogleGenerativeAI(this.apiKey);
    }
  }

  /**
   * Processes an audio file using the Gemini API via a Cloud Storage URL
   * Uses the server API to securely process the audio
   * 
   * @param audioUrl - The Google Cloud Storage URL of the audio file
   * @param options - Optional processing options
   * @returns Promise with the transcription, summary, and extracted tasks
   */
  async processAudioFromUrl(audioUrl: string, options?: {
    language?: string;
    taskExtraction?: boolean;
    summaryLength?: 'short' | 'medium' | 'long';
  }): Promise<TranscriptionResult> {
    try {
      // For demo mode, return mock results without hitting the API
      if (process.env.NEXT_PUBLIC_DEMO_MODE === 'true') {
        console.log(`[DEMO MODE] Simulating processing of audio from URL: ${audioUrl}`);
        
        // Simulate processing delay
        await new Promise(resolve => setTimeout(resolve, 3000));
        
        return this.getMockResults(audioUrl);
      }
      
      // Call the server API to process the audio
      const response = await fetch('/api/process', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          audioUrl,
          options
        })
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        let errorData;
        try {
          errorData = JSON.parse(errorText);
          console.error('Detailed API error:', errorData);
        } catch (e) {
          errorData = { raw: errorText };
          console.error('Non-JSON error response:', errorText);
        }
        throw new Error(errorData.error || errorData.details?.message || 'Audio processing failed: ' + JSON.stringify(errorData));
      }
      
      return await response.json();
      
    } catch (error) {
      console.error('Error processing audio with Gemini API:', error);
      throw new Error(error instanceof Error ? error.message : 'Unknown error during Gemini API processing');
    }
  }
  
  /**
   * Ask a follow-up question about a transcribed audio recording
   * 
   * @param transcription - The original transcription text
   * @param question - The user's question about the content
   * @returns Promise with the answer text
   */
  async askQuestion(transcription: string, question: string): Promise<string> {
    try {
      // For demo mode, return mock answers
      if (process.env.NEXT_PUBLIC_DEMO_MODE === 'true') {
        console.log(`[DEMO MODE] Simulating question answering: "${question}"`);
        
        // Simulate processing delay
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        return this.getMockAnswer(transcription, question);
      }
      
      // Call the server API to ask the question
      const response = await fetch('/api/ask', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          transcription,
          question
        })
      });
      
      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Question answering failed');
      }
      
      const result = await response.json();
      return result.answer;
      
    } catch (error) {
      console.error('Error processing question with Gemini API:', error);
      throw new Error(error instanceof Error ? error.message : 'Unknown error processing question');
    }
  }
  
  /**
   * Generate mock results for demo mode
   * @param audioUrl - The audio URL being processed
   * @returns Mock transcription result
   */
  private getMockResults(audioUrl: string): TranscriptionResult {
    return {
      transcription: "This is a simulated transcription of the audio recording that would have been processed by the Gemini API using the audio file located at " + audioUrl + ". In a real implementation, this would contain the actual speech content from the recording, including all spoken words, filler sounds, and potentially speaker identification.",
      summary: "This is a mock summary that would be generated by Gemini based on the content of the audio recording. It would highlight the main points, key information, and important context from the transcription.",
      tasks: [
        { 
          id: "task_" + Date.now() + "_1", 
          text: "Follow up with marketing team about Q2 campaign launch", 
          deadline: this.generateRandomFutureDate() 
        },
        { 
          id: "task_" + Date.now() + "_2", 
          text: "Complete the project proposal draft", 
          deadline: this.generateRandomFutureDate() 
        },
        { 
          id: "task_" + Date.now() + "_3", 
          text: "Schedule team sync meeting for next sprint planning", 
          deadline: this.generateRandomFutureDate() 
        }
      ]
    };
  }
  
  /**
   * Generate mock answers for demo mode
   */
  private getMockAnswer(transcription: string, question: string): string {
    // Generate a contextual response based on the question
    if (question.toLowerCase().includes("deadline") || question.toLowerCase().includes("due")) {
      return "Based on your recording, there appear to be several deadlines mentioned: the marketing campaign materials are due by the end of this week, and the project proposal needs to be submitted by the 15th of next month.";
    } else if (question.toLowerCase().includes("meeting") || question.toLowerCase().includes("schedule")) {
      return "According to your recording, you mentioned scheduling a team meeting for next Monday at 10 AM to discuss the quarterly planning.";
    } else if (question.toLowerCase().includes("priority") || question.toLowerCase().includes("important")) {
      return "From your recording, the highest priority item appears to be finalizing the client presentation before Thursday's meeting.";
    } else {
      return "Based on the transcription, you discussed project timelines, team coordination, and upcoming client deliverables. You mentioned needing to follow up with several team members about their progress.";
    }
  }
  
  /**
   * Helper method to generate random future dates for demo purposes
   */
  private generateRandomFutureDate(): string {
    const today = new Date();
    const futureDate = new Date(today);
    futureDate.setDate(today.getDate() + Math.floor(Math.random() * 14) + 1); // Random date 1-14 days in future
    
    return futureDate.toLocaleDateString('en-US', { 
      year: 'numeric', 
      month: 'long', 
      day: 'numeric' 
    });
  }
}
